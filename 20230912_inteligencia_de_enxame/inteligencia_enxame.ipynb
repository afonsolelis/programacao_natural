{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 5 - Inteligência de Enxame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideia Central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"Inteligência\" que surge da interação entre agentes que, individualmente, não apresentam esta característica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I - ACO (Ant Colony Optimization)\n",
    "\n",
    "#### Metáfora\n",
    "- O uso de ferômonios como marcadores ambientais;\n",
    "- Deslocamento das formigas dependente da concentração de feromônios localmente;\n",
    "\n",
    "#### A probabilidade de uma formiga sair do ponto Xi ao ponto Xj\n",
    "\n",
    "\\[ P_{ij} = \\frac{{(\\eta_{ij}^\\alpha) \\cdot (N_{ij}^\\beta)}}{{\\sum_k{(\\eta_{ik}^\\alpha) \\cdot (N_{ik}^\\beta)}}} \\]\n",
    "\n",
    "\n",
    "Nesta equação:\n",
    "\n",
    "* PijP_{ij}Pij​ representa a probabilidade de uma formiga se mover do ponto xix_ixi​ para o ponto xjx_jxj​.\n",
    "* ηij\\eta_{ij}ηij​ é a visibilidade do arco (xi, xj), geralmente definida como a inversa da distância entre xix_ixi​ e xjx_jxj​.\n",
    "* NijN_{ij}Nij​ é o nível de feromônio no arco (xi, xj).\n",
    "* α\\alphaα e β\\betaβ são parâmetros que controlam a influência relativa da visibilidade e do feromônio na probabilidade de movimento das formigas.\n",
    "* A soma no denominador (∑k\\sum_k∑k​) é uma soma sobre todos os arcos possíveis que uma formiga pode visitar a partir de xix_ixi​. Isso normaliza as probabilidades, garantindo que a probabilidade total de movimento seja igual a 1.\n",
    "\n",
    "---\n",
    "Após todas as formigas terem feito suas rotas, é calculada uma variação deltaEtaij para a quantidade de feromônio no trecho Xi -> Xj\n",
    "\n",
    "* deltaEtaij pode ser calculada de diversas maneiras:\n",
    "\n",
    "1. Adicionar uam quantidade fica **Q** para cada formiga que recorreu Xi -> Xj.\n",
    "2. Adicionar **Q/Tk**, sendo **Q** fixo para cada formiga **k** que percorreu Xi -> Xj sendo **Tk** o comprimento total de sua rota.\n",
    "3. O mesmo anterior, mas só há variação para os trechos Xi -> Xj que pertencem à melhor rota encontrada.\n",
    "\n",
    "As quantidades de feromônios são atualizadas:\n",
    "\n",
    "Etaij <- (1-p)Etaij + DeltaEtaij\n",
    "\n",
    "em que o p é uma taxa de decaimento entre 0 e 1\n",
    "\n",
    "Por final repita até alcançar um critério de parada.\n",
    "---\n",
    "\n",
    "#### Exemplo: ACO Aplicado ao TSP (Traveling Salesman Problem)\n",
    "\n",
    "Dado um conjunto de pontos e o custo de deslocamento entre um ponto e outro, encontrar uma rota que percorra todos os pontos com custo mínimo.\n",
    "\n",
    "O problema do Caixeiro Viajante (TSP) é um dos problemas de otimização mais conhecidos e desafiadores. Ele envolve encontrar o caminho mais curto que visita todas as cidades em um conjunto exatamente uma vez e retorna à cidade de origem. Vamos explorar como o Ant Colony Optimization (ACO) pode ser aplicado a este problema clássico.\n",
    "\n",
    "Definição do Problema TSP:\n",
    "\n",
    "Suponha que temos um conjunto de cidades e as distâncias entre todas as possíveis duplas de cidades são conhecidas. O objetivo é encontrar a ordem de visitação das cidades que minimize a distância total percorrida, começando e terminando na mesma cidade.\n",
    "\n",
    "Aplicação do ACO ao TSP:\n",
    "\n",
    "Aqui estão os passos principais para aplicar o ACO ao TSP:\n",
    "\n",
    "Modelagem do Problema: Cada formiga virtual representa uma possível rota para o caixeiro viajante. Inicialmente, todas as formigas começam em cidades diferentes.\n",
    "\n",
    "Caminhos e Feromônios: Para cada par de cidades, há um caminho associado a ele e uma quantidade de feromônio. No início, os feromônios são definidos com um valor inicial arbitrário.\n",
    "\n",
    "Ciclo de Busca: As formigas virtuais começam a construir suas rotas passo a passo. Em cada passo, uma formiga escolhe a próxima cidade com base nas informações locais (distância para a cidade próxima) e nas informações globais (feromônio presente nos caminhos).\n",
    "\n",
    "Atualização de Feromônio: Após cada ciclo de busca, as formigas atualizam a quantidade de feromônio nos caminhos com base na qualidade das soluções encontradas. Caminhos que fazem parte da rota da melhor solução recebem uma atualização maior de feromônio.\n",
    "\n",
    "Evolução da Colônia: Com o tempo, a concentração de feromônio nos caminhos mais curtos aumenta, tornando esses caminhos mais atraentes para as formigas. A colônia tende a convergir para uma solução que representa a rota ótima.\n",
    "\n",
    "Resultados Esperados:\n",
    "\n",
    "O ACO aplicado ao TSP tem o potencial de encontrar soluções de alta qualidade para o problema, especialmente em instâncias onde a busca exaustiva seria computacionalmente inviável devido a um grande número de cidades. O algoritmo é capaz de explorar diferentes caminhos e, com o tempo, convergir para um caminho ótimo ou subótimo, dependendo da configuração dos parâmetros.\n",
    "\n",
    "No entanto, a eficácia do ACO no TSP depende da escolha adequada dos parâmetros, como a taxa de evaporação de feromônio, a influência do feromônio nas escolhas das formigas e o número de formigas. Ajustar esses parâmetros corretamente é crucial para obter os melhores resultados.\n",
    "\n",
    "Em resumo, o ACO é uma abordagem poderosa para resolver o problema do Caixeiro Viajante e muitos outros problemas de otimização combinatória, aproveitando o comportamento das formigas virtuais para encontrar soluções eficientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemplo detalhado TSP com ACO\n",
    "\n",
    "Primeiro, você precisará instalar o pacote `ant-colony-optimization`. Você pode fazer isso usando o `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ant-colony-optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está o código de exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from aco import AntColony\n",
    "\n",
    "# Define as cidades e suas coordenadas (x, y)\n",
    "cities = {\n",
    "    \"A\": (0, 0),\n",
    "    \"B\": (2, 4),\n",
    "    \"C\": (5, 2),\n",
    "    \"D\": (7, 8),\n",
    "    \"E\": (1, 6),\n",
    "}\n",
    "\n",
    "# Calcula a matriz de distâncias entre as cidades\n",
    "num_cities = len(cities)\n",
    "distances = np.zeros((num_cities, num_cities))\n",
    "\n",
    "for i in range(num_cities):\n",
    "    for j in range(num_cities):\n",
    "        if i != j:\n",
    "            x1, y1 = cities[list(cities.keys())[i]]\n",
    "            x2, y2 = cities[list(cities.keys())[j]]\n",
    "            distances[i][j] = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2)\n",
    "\n",
    "# Configuração do ACO\n",
    "aco = AntColony(num_ants=10, num_iterations=100, alpha=1.0, beta=3.0, rho=0.5, q0=0.7)\n",
    "\n",
    "# Executa o ACO para resolver o TSP\n",
    "best_tour, best_distance = aco.solve(distances)\n",
    "\n",
    "# Exibe a rota encontrada e a distância total\n",
    "print(\"Melhor rota encontrada:\", best_tour)\n",
    "print(\"Distância total da rota:\", best_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo:\n",
    "\n",
    "1. Definimos um conjunto de cidades e suas coordenadas (x, y).\n",
    "2. Calculamos a matriz de distâncias entre todas as cidades com base nas coordenadas.\n",
    "3. Configuramos o ACO com parâmetros como o número de formigas, o número de iterações, os parâmetros de influência alfa e beta, a taxa de evaporação de feromônio (rho) e o parâmetro q0.\n",
    "4. Executamos o ACO para encontrar a melhor rota para o problema TSP.\n",
    "5. Exibimos a rota encontrada e a distância total.\n",
    "\n",
    "Lembre-se de que este é um exemplo simples para fins de demonstração. Para problemas TSP mais complexos, você pode precisar ajustar os parâmetros do ACO e considerar estratégias adicionais, como a inclusão de heurísticas específicas do problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detalhamento\n",
    "\n",
    "O Ant Colony Optimization (ACO) é uma técnica de otimização inspirada no comportamento das formigas reais, que é utilizada para resolver problemas de otimização combinatória, como o problema do caixeiro-viajante, roteamento de veículos, programação de horários e muitos outros. O ACO foi proposto por Marco Dorigo em 1992 e é um dos algoritmos populares na área de otimização.\n",
    "\n",
    "A ideia central do ACO é modelar a busca por soluções ótimas como o comportamento de formigas que procuram por comida. Aqui estão os principais componentes e conceitos do ACO:\n",
    "\n",
    "1. **Colônia de Formigas Virtuais:** No ACO, não estamos trabalhando com formigas reais, mas com formigas virtuais que existem apenas no contexto do algoritmo. Cada formiga virtual representa uma possível solução para o problema de otimização.\n",
    "    \n",
    "2. **Caminhos e Feromônios:** As formigas virtuais percorrem caminhos em busca da solução ótima. Cada caminho é associado a um valor chamado \"feromônio\". Os caminhos com uma maior concentração de feromônio são mais atraentes para as formigas.\n",
    "    \n",
    "3. **Exploração e Exploração:** As formigas podem seguir dois tipos de comportamento: exploração e exploração. Na exploração, uma formiga escolhe um caminho com base nas informações locais (por exemplo, quão próximo o próximo ponto é). Na exploração, uma formiga escolhe um caminho com base na quantidade de feromônio presente no caminho.\n",
    "    \n",
    "4. **Atualização de Feromônio:** Após cada ciclo de busca, as formigas virtuais atualizam a quantidade de feromônio nos caminhos com base na qualidade das soluções encontradas. Caminhos que levam a soluções melhores recebem uma atualização de feromônio maior.\n",
    "    \n",
    "5. **Evolução da Colônia:** Com o tempo, a colônia de formigas virtuais tende a convergir para a solução ótima, uma vez que os caminhos com melhores soluções acumulam mais feromônio, tornando-se mais atraentes para as formigas.\n",
    "    \n",
    "6. **Exploração Global vs. Local:** O ACO equilibra a exploração global (exploração de todo o espaço de busca) com a exploração local (concentração em regiões promissoras). Isso é alcançado por meio de parâmetros como a taxa de evaporação de feromônio e a influência do feromônio nas escolhas das formigas.\n",
    "    \n",
    "7. **Parametrização:** O ACO envolve a parametrização de vários fatores, como a taxa de evaporação de feromônio, a quantidade inicial de feromônio, os pesos das informações locais e globais, entre outros. A escolha adequada desses parâmetros é essencial para o desempenho do algoritmo.\n",
    "    \n",
    "\n",
    "O ACO é aplicável a uma ampla gama de problemas de otimização combinatória e é conhecido por encontrar soluções de alta qualidade. No entanto, o ACO pode ser sensível à escolha de parâmetros e pode exigir ajustes para obter o melhor desempenho em problemas específicos. Além disso, o ACO é um algoritmo baseado em população, o que significa que requer a manutenção de múltiplas soluções candidatas ao mesmo tempo. Portanto, ele pode ser computacionalmente intensivo em problemas de grande escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./../assets/formigas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO (Particle Swam Optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O PSO, ou Particle Swarm Optimization, é um algoritmo de otimização que foi inspirado no comportamento social de enxames de pássaros e cardumes de peixes. Ele faz parte de um grupo de algoritmos de otimização baseados em população que são usados para encontrar soluções aproximadas para problemas complexos de otimização.\n",
    "\n",
    "No PSO, uma população de soluções candidatas (partículas) é inicializada e movida através do espaço de busca em direção a uma solução ótima, com base na experiência coletiva das partículas. Cada partícula mantém uma posição e uma velocidade no espaço de busca, e essas informações são usadas para atualizar sua posição de acordo com seu desempenho e o desempenho das partículas vizinhas.\n",
    "\n",
    "As principais características do PSO incluem:\n",
    "\n",
    "1. **População de Partículas:** Um conjunto de soluções candidatas é criado, cada uma representada por uma partícula.\n",
    "    \n",
    "2. **Posição e Velocidade:** Cada partícula mantém sua posição atual e uma velocidade que indica a direção e a magnitude de seu movimento.\n",
    "    \n",
    "3. **Função de Fitness:** Um critério de avaliação (função de fitness) é usado para medir o quão boa é a solução representada pela posição da partícula no espaço de busca.\n",
    "    \n",
    "4. **Melhor Posição Pessoal (pBest):** Cada partícula mantém o registro de sua melhor posição pessoal com base em sua avaliação de fitness até o momento.\n",
    "    \n",
    "5. **Melhor Posição Global (gBest):** A melhor posição global entre todas as partículas da população é rastreada.\n",
    "    \n",
    "6. **Atualização das Partículas:** As partículas são atualizadas iterativamente, movendo-se em direção à sua melhor posição pessoal (pBest) e à melhor posição global (gBest). Isso é feito usando equações que combinam a velocidade atual, a posição atual e as informações das melhores posições.\n",
    "    \n",
    "7. **Convergência:** O algoritmo continua iterando até atender a um critério de parada, geralmente um número máximo de iterações ou uma convergência satisfatória.\n",
    "    \n",
    "\n",
    "O PSO é amplamente utilizado em problemas de otimização em que a busca por uma solução ótima é complicada por um grande espaço de busca ou pela complexidade da função objetivo. Ele tem aplicações em áreas como otimização de parâmetros, treinamento de redes neurais, design de antenas, roteamento de veículos, entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](./../assets/pso.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício - Aula 5 – Inteligência de Enxame\n",
    "\n",
    "Considere a função de duas variáveis reais \\(x\\) e \\(y\\) definidas por:\n",
    "\n",
    "\\[\n",
    "f(x, y) = (x^2 + y - 11)^2 + (x + y^2 - 7)^2\n",
    "\\]\n",
    "\n",
    "(Função de Himmelblau) com \\(-5 \\leq x, y \\leq 5\\). Implemente um PSO para buscar valores de \\(x\\) e \\(y\\) que minimizam a função \\(f\\). Varie os parâmetros de \"inércia cognitiva\" e \"inércia social\" e analise a qualidade das soluções encontradas, bem como a quantidade de iterações necessárias para chegar a essas soluções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir a função de Himmelblau\n",
    "def himmelblau(x, y):\n",
    "    return (x**2 + y - 11)**2 + (x + y**2 - 7)**2\n",
    "\n",
    "# Parâmetros do PSO\n",
    "num_particles = 30\n",
    "max_iter = 100\n",
    "w = 0.5  # Inércia cognitiva\n",
    "c1 = 1.5  # Coeficiente de influência cognitiva (inércia pessoal)\n",
    "c2 = 1.5  # Coeficiente de influência social (inércia social)\n",
    "\n",
    "# Inicialização das partículas\n",
    "particles = np.random.uniform(-5, 5, size=(num_particles, 2))\n",
    "velocities = np.random.uniform(-1, 1, size=(num_particles, 2))\n",
    "personal_best_positions = particles.copy()\n",
    "personal_best_values = np.array([himmelblau(x, y) for x, y in particles])\n",
    "global_best_idx = np.argmin(personal_best_values)\n",
    "global_best_position = personal_best_positions[global_best_idx]\n",
    "global_best_value = personal_best_values[global_best_idx]\n",
    "\n",
    "# Execução do PSO\n",
    "for iteration in range(max_iter):\n",
    "    for i in range(num_particles):\n",
    "        # Atualizar a velocidade da partícula\n",
    "        r1, r2 = np.random.rand(), np.random.rand()\n",
    "        velocities[i] = (w * velocities[i] +\n",
    "                          c1 * r1 * (personal_best_positions[i] - particles[i]) +\n",
    "                          c2 * r2 * (global_best_position - particles[i]))\n",
    "        \n",
    "        # Atualizar a posição da partícula\n",
    "        particles[i] = particles[i] + velocities[i]\n",
    "        \n",
    "        # Avaliar a nova posição\n",
    "        current_value = himmelblau(particles[i, 0], particles[i, 1])\n",
    "        \n",
    "        # Atualizar o melhor valor pessoal e posição\n",
    "        if current_value < personal_best_values[i]:\n",
    "            personal_best_values[i] = current_value\n",
    "            personal_best_positions[i] = particles[i]\n",
    "        \n",
    "        # Atualizar o melhor valor global e posição\n",
    "        if current_value < global_best_value:\n",
    "            global_best_value = current_value\n",
    "            global_best_position = particles[i]\n",
    "    \n",
    "    print(f\"Iteração {iteration+1}: Melhor valor = {global_best_value:.4f}\")\n",
    "\n",
    "print(f\"Solução encontrada: x = {global_best_position[0]:.4f}, y = {global_best_position[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
